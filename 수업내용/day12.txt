from bs4 import BeautifulSoup
import re
req = requests.get('https://movie.naver.com/movie/point/af/list.nhn?page=1')
html =req.text
soup = BeautifulSoup(html, 'html.parser')
titles = soup.select('.moive')
points = soup.select('td.title > div > em')
reviews = soup.select('td.title')
 

movie_title=[]
movie_point=[]
movie_review=[]
for dom in titles :
     movie_title.append(dom.text)

for dom in points :
     movie_point.append(dom.text)

for dom in reviews :
     content = dom.contents[6]  
     content = re.sub("[\n\t]", "", content)   
     content = re.sub("신고", "", content)
     movie_review.append(content)

for i  in range(len(movie_title)) :
    print('영화제목:' , movie_title[i])
    print('평점:' , movie_point[i])
    print('리뷰:' , movie_review[i])
    print('-----------------------------------------')




#######################################################
bs4.element.Tag.string
bs4.element.Tag.text
bs4.element.Tag.name
bs4.element.Tag.attrs
bs4.element.Tag.contents
bs4.element.Tag.strings
bs4.element.Tag.stripped_strings
bs4.element.Tag.string.strip()
bs4.element.Tag.text.trip()
bs4.element.Tag.get_text()
bs4.element.Tag.get_text(strip=True)
bs4.element.Tag.parent
bs4.element.Tag.children
bs4.element.Tag.next_sibling
bs4.element.Tag.previous_siblings
bs4.element.Tag.descendants


find()
find_all()
find_parent()
find_parents()
find_next_siblings()
find_next_sibling()
find_previous_siblings()
find_previous_sibling()
find_all_next()
find_next()
find_all_previous()
find_previous()
select()  #css선택자


################################################## 

#exam1.py

html_doc = """
<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Test BeautifulSoup</title>
    </head>
    <body>
        <h1>테스트</h1>
    </body>
</html> """

from bs4 import BeautifulSoup
bs = BeautifulSoup(html_doc, 'html.parser')
print(type(bs))  

 

 

#exam2.py

html_doc = """
<!DOCTYPE html>
<html>
     <head>
          <meta charset=‘utf-8’>
          <title>Test BeautifulSoup</title>
     </head>
     <body>
          <p align="center">P태그의 콘텐츠</p>
          <img src="http://unico2013.dothome.co.kr/image/flower.jpg"width="300"> 
     </body>
</html> """

from bs4 import BeautifulSoup
bs = BeautifulSoup(html_doc, 'html.parser')
print(bs.prettify())

 

 

 

#exam3.py

html_doc = """
<!DOCTYPE html>
<html>
     <head>
          <meta charset='utf-8'>
          <title>Test BeautifulSoup</title>
     </head>
     <body>
          <p align="center">P태그의 콘텐츠</p>
          <img src="http://unico2013.dothome.co.kr/image/flower.jpg" width="300">
          <ul>
               <li>테스트1<strong>강조</strong></li>
               <li>테스트2</li>
               <li>테스트3</li>
          </ul>
     </body>
</html> """ 

from bs4 import BeautifulSoup
bs = BeautifulSoup(html_doc, 'html.parser')
print(type(bs.title), ':', bs.title)
print(type(bs.title.name), ':', bs.title.name)
print(type(bs.title.string), ':', bs.title.string)
print('-------------------------')
print(type(bs.p['align']), ':', bs.p['align'])
print(type(bs.img['src']), ':', bs.img['src'])
print(type(bs.img.attrs), ':', bs.img.attrs)

 

 

#exam4.py

html_doc = """
<!DOCTYPE html>
<html>
     <head>
          <meta charset='utf-8'>
          <title>Test BeautifulSoup</title>
     </head>
     <body>
          <p align="center">P태그의 콘텐츠</p>
          <img src="http://unico2013.dothome.co.kr/image/flower.jpg" width="300">
          <ul>
               <li>테스트1<strong>강조</strong></li>
               <li>테스트2</li>
               <li>테스트3</li>
          </ul>
     </body>
</html> """

 
from bs4 import BeautifulSoup
bs = BeautifulSoup(html_doc, 'html.parser')
print("[ string 속성 ]")
print(type(bs.p.string), ':', bs.p.string)
print(type(bs.ul.string), ':', bs.ul.string)
print(type(bs.ul.li.string), ':', bs.ul.li.string)
print(type(bs.ul.li.strong.string), ':', bs.ul.li.strong.string)
print("[ text 속성 ]")
print(type(bs.p.text), ':', bs.p.text)
print(type(bs.ul.text), ':', bs.ul.string)
print(type(bs.ul.li.text), ':', bs.ul.li.text)
print(type(bs.ul.li.strong.text), ':', bs.ul.li.strong.text)
print("[ contents 속성 ]")
print(type(bs.p.contents), ':', bs.p.contents)
print(type(bs.ul.contents), ':', bs.ul.string)
print(type(bs.ul.li.contents), ':', bs.ul.li.contents)
print(type(bs.ul.li.strong.contents), ':', bs.ul.li.strong.contents)

 

 

# exam5.py

html_doc = """

<!DOCTYPE html>

<html>

     <head>

          <meta charset='utf-8'>

          <title>Test BeautifulSoup</title>

     </head>

     <body>

          <p>

              Beautiful Soup은 HTML 및 XML 파일에서

              데이터를 추출하기 위한 

              파이썬 라이브러리입니다.  

              <i>웹 크롤링</i>                       

          </p>

     </body>

</html> """

from bs4 import BeautifulSoup

bs = BeautifulSoup(html_doc, 'html.parser')

print('[ strings]')

print(type(bs.p.strings), ':', bs.p.strings)

for data in bs.p.strings:

     print('[', data, ']')

print('[ stripped_strings]')

print(type(bs.p.stripped_strings), ':', bs.p.stripped_strings)

for data in bs.p.stripped_strings:

     print('[', data, ']')

 

 

 

#exam6.py

html_doc = """

<!DOCTYPE html>

<html>

   <head>

      <meta charset='utf-8'>

      <title>Test BeautifulSoup</title>

   </head>

   <body>

      <section>

        <h1>테스트</h1>

        <div>

          <ol>

            <li>리스트1</li>

            <li>리스트2</li>

            <li>리스트3</li>

</div>

        <aside>기타 등등</aside>

      </section>

   </body>

</html> """ 

 

 

from bs4 import BeautifulSoup

bs = BeautifulSoup(html_doc, 'html.parser')

print('[ 부모 태그 ]')

print(type(bs.title.parent.name), ':', bs.title.parent.name)

print(type(bs.section.parent.name), ':', bs.section.parent.name)

print(type(bs.section.h1.string.parent.name), ':', bs.section.h1.string.parent.name)

print('[ 형제 태그 ]')

print(bs.section.div.next_sibling.name)

print(bs.section.div.previous_sibling.name)

print(bs.section.div.next_sibling.next_sibling.name)

print(bs.section.div.previous_sibling.previous_sibling.name)

print('[ 형제 태그들 ]')

litag = bs.section.div.ol.li

print('찾은 태그 : ', litag)

count = 1

for sibling in litag.next_siblings:

    print('형제 ',count,' : ', repr(sibling))

    count = count+1 

 

 

 

 

#exam7.py

html_doc = """

<!DOCTYPE html>

<html>

   <head>

      <meta charset='utf-8'>

      <title>Test BeautifulSoup</title>

   </head>

   <body>

      <section>

        <h1>테스트</h1>

        <div>

          <ol>

            <li>리스트1</li>

            <li>리스트2</li>

            <li>리스트3</li>

</div>

        <aside>기타 등등</aside>

      </section>

   </body>

</html> """ 

from bs4 import BeautifulSoup

bs=BeautifulSoup(html_doc, 'html.parser')

t1=bs.section.div.next_element

t2=t1.next_element; t3=t2.next_element

t4=t3.next_element; t5=t4.next_element

print(t1.name); print(t2.name)

print(t3.name); print(t4.name)

print(t5.name)

print('-----------------------------')

print(bs.section.div.children)

print('자식 DOM 객체의 개수 : ', len(tuple(bs.section.div.children)))

count = 1

for data in bs.section.div.children:

    print('자식 ',count,' : ',repr(data))

    count = count+1

print('-----------------------------')

print(bs.section.div.descendants)

print('자손 DOM 객체의 개수 : ', len(tuple(bs.section.div.descendants)))

 

 
 
 

#exam8.py

html_doc="""

<!DOCTYPE html>

<html>

  <head>

     <meta charset='utf-8'>

     <title>Test BeautifulSoup</title>

  </head>

  <body>

     <p align="center"> text contents </p>

     <p align="right">  text contents 2 </p>

     <p align="left">   text contents 3 </p>

     <img src="http://unico2013.dothome.co.kr/image/flower.jpg" width="500">

     <div>

       <p>text contents 4</p> 

     </div>

  </body>

</html> """

from bs4 import BeautifulSoup

bs = BeautifulSoup(html_doc, 'html.parser')

print(type(bs.find('p')))

print(type(bs.find_all('p')))

print("---------------------------------")

print(bs.find('title'))

print(bs.find('p'))

print(bs.find('img'))

print("---------------------------------")

ptags = bs.find_all('p')

print(ptags)

print("----------------")

for tag in ptags :

    print(tag)

 

 

 

 

#exam9.py

html_doc="""

<!DOCTYPE html>

<html>

  <head>

      <meta charset='utf-8'>

      <title>Test BeautifulSoup</title>

  </head>

  <body>

     <section>

       <p align="center"> text contents </p>

       <p align="right">  text contents 2 </p>

       <p align="left">   text contents 3 </p>

       <img src="http://unico2013.dothome.co.kr/image/flower.jpg" width="500">

       <div>

          <p>text contents 4</p> 

       </div>

</section>

  </body>

</html> ""

from bs4 import BeautifulSoup

bs = BeautifulSoup(html_doc, 'html.parser')

body_tag = bs.find('section')

list1 = body_tag.find_all(['p','img'])

for tag in list1:

    print(tag) 

print("------------------------------------------")

body_tag = bs.find('div')

list2 = body_tag.find_all('p')

for tag in list2:

    print(tag)

 

 

 

 

# exam10.py

html="""

<!DOCTYPE html>

<html>

  <head>

     <meta charset='utf-8'>

     <title>Test BeautifulSoup</title>

  </head>

  <body>

     <p align="center"> text contents </p>

     <p align="right" class="myp">  text contents 2 </p>

     <p align="left" a="b">   text contents 3 </p>

     <img src="http://unico2013.dothome.co.kr/image/flower.jpg" width="500">

  </body>

</html> """

 

from bs4 import BeautifulSoup

bs = BeautifulSoup(html, 'html.parser')

print(bs.find('p', align="center"))

print(bs.find('p', class_="myp"))

print(bs.find('p', align="left"))

print("-------------------------------------")

print(bs.find('p', attrs={"align":"center"}))

print(bs.find('p', attrs={"align":"right", "class":"myp"}))

print(bs.find('p', attrs={"align":"left"}))

 

 

 

#exam11.py

html="""

<!DOCTYPE html>

<html>

  <head>

     <meta charset='utf-8'>

     <title>Test BeautifulSoup</title>

  </head>

  <body>

     <p align="center">     text contents가나다 </p>

     <img src="http://unico2013.dothome.co.kr/image/flower.jpg" 

                             width="500">

  </body>

</html> """

from bs4 import BeautifulSoup

bs = BeautifulSoup(html, 'html.parser')

ptag = bs.find('p')

print(ptag.name)

print("----------------------------------------")

print(ptag.string)

print(ptag.string.strip())

print("----------------------------------------")

print(ptag.text)

print(ptag.text.strip())

print("----------------------------------------")

print(ptag.get_text(strip=True))

 

 

 

#exam12.py

html="""

<!DOCTYPE html>

<html>

  <head>

     <meta charset='utf-8'>

     <title>Test BeautifulSoup</title>

  </head>

  <body>

     <p class="pstyle black"  align="left"> text contents 1 </p>

     <p class="pstyle yellow" align="right"> text contents 2 </p>

     <p class="pstyle red"    align="center"> text contents 3 </p>

     <img src="http://unico2013.dothome.co.kr/image/flower.jpg" width="500">

  </body>

</html> """

from bs4 import BeautifulSoup

bs = BeautifulSoup(html,'html.parser')

ptag = bs.find('p')

print(type(ptag))

print(ptag['class'])

print(ptag['align'])

print(ptag.attrs)

imgtag = bs.find('img')

print(type(imgtag))

print(imgtag['src'])

print(imgtag['width'])

print(imgtag.attrs)

 

 

 

#exam14.py

from bs4 import BeautifulSoup

doc = ['<html><head><title>Page title</title></head>', \

    '<body><p id="firstpara" align="center">This is paragraph <b>one</b></p>', \

    '<p id="secondpara" align="blah">This is a paragraph <b>two</b></p>', '</html>']

 

bs = BeautifulSoup("".join(doc), 'html.parser')

import re

tagsStartingWithB = bs.find_all(re.compile('^b'))

for tag in tagsStartingWithB :

    print(tag.name)

 

tagsEndingId = bs.find_all(id=re.compile("para$"))

for tag in tagsEndingId :

    print(tag.name)

 

 

 

#exam15.py

import requests
from bs4 import BeautifulSoup 

req = requests.get('http://unico2013.dothome.co.kr/crawling/exercise_css.html')
html = req.content
print(type(html))
html = html.decode('utf-8')
#print(html)
print("==============================")
bs = BeautifulSoup(html, 'html.parser')
title = bs.select('h1')
title1 = bs.select('#f_subtitle')
title2 = bs.select('.subtitle')
title3 = bs.select('aside > h2')
img = bs.select('[src]') 

print(type(title))
print(type(title[0]))
print("<h1>태그의 개수 : %d " %len(title))
print("f_subtitle이라는 id 속성을 갖는 태그 개수 : %d " %len(title1))
print("subtitle이라는 class 속성을 갖는 태그 개수 : %d " %len(title2))
print("aside 태그의 <h2> 자식 태그 개수 : %d " %len(title3))
print("src 속성을 갖는 태그 개수 : %d " %len(img))

for content in title:
    print(content.string)
print("------------------------------")

for content in title1:
    print(content.text)
print("------------------------------")

for content in title2:
    print(content.text)
print("------------------------------")

for content in title3:
    print(content.text)
print("------------------------------")

for content in img:
   print(content["src"])


 




##################밀도 기반 군집 분석 (DBSCAN) ################
데이터가 모여 있는 밀도가 높은 공간(반경 r안에 샘플 개수 설정함)에 클러스터 레이블을 할당
import pandas as pd
import folium

file_path='./datas/2016_middle_shcool_graduates_report.xlsx'
df =pd.read_excel(file_path, header=0)

print(df.info())
print(df.columns.values)


#참고 url : http://python-graph-gallery.com/288-map-background-with-folium
mschool_map = folium.Map(location=[37.55, 126.98],  tiles='Stamen Terrain', zoom_start=12)
for name, lat, lng in zip (df.학교명, df.위도, df. 경도) :
    folium.CircleMarker([lat, lng],
                              radius=5,
                              color='brown',
                              fill=True,
                              fill_color='yellow',
                              fill_opacity=0.5,
                              popup=name).add_to(mschool_map)

mschool_map.save('./output/seoul_mschool_location.html')

#지역, 코드, 유형, 주야 등 변수의 one-hot-encoding으로 dummy 변수 변환
#LabelEncoder는 문자를 0부터 시작하는 정수형 숫자로 바꿔주는 기능을 제공 (반대 연산도 가능)

from sklearn import preprocessing

label_encoder = preprocessing.LabelEncoder() 
onehot_encoder = preprocessing.OneHotEncoder()

onehot_location = label_encoder.fit_transform(df['지역'])

onehot_code = label_encoder.fit_transform(df['코드'])
onehot_type = label_encoder.fit_transform(df['유형'])
onehot_day= label_encoder.fit_transform(df['주야'])

df['location'] = onehot_location
df['code'] = onehot_code
df['type'] = onehot_type
df['day'] = onehot_day

print(df.head())
print(df.info())

#DBSCAN 군집분석 수행
from sklearn import cluster
#분석에 사용할 속성 [과학고, 외고_국제고, 자사고 ] 진학률
column_list = [9, 10, 13]
X = df.iloc[ : , column_list]
print(X[:5])

# 설명변수 정규화
X= preprocessing.StandardScaler().fit(X).transform(X)
dbscan_model = cluster.DBSCAN(eps=0.2, min_samples=5)
dbscan_model.fit(X)

cluster_label = dbscan_model.labels_
print(cluster_label)

df['Cluster'] = cluster_label
print(df.head())
print('\n')
#클러스터값으로  그룹화하여 출력
grouped_cols =[0, 1, 3] +column_list
grouped = df.groupby('Cluster')
for key, group in grouped:
    print('* key : ' , key)
    print('* number : ' , len(group))
    print(group.iloc[:, grouped_cols].head())
    print('\n')

colors = {-1:'gray', 0:'coral', 1:'black', 2:'green', 3:'red', 4:'purple', 5:'orange', 6:'brown', 7:'magenta', 8:'yellow', 9:'brick', 10:'cyan', 11:'pink'}
cluster_map = folium.Map(location=[37.55, 126.98],  tiles='Stamen Terrain', zoom_start=12)

for name, lat, lng, clus in zip (df.학교명, df.위도, df. 경도, df.Cluster) :
    folium.CircleMarker([lat, lng],
                              radius=5,
                              color=colors[clus],
                              fill=True,
                              fill_color=colors[clus] ,
                              fill_opacity=0.5,
                              popup=name).add_to(cluster_map)

cluster_map.save('./output/seoul_mschool_cluster.html')




####LabelEncoder 예제
#LabelEncoder는 문자를 0부터 시작하는 정수형 숫자로 바꿔주는 기능을 제공 (반대 연산도 가능)
import numpy as np
from sklearn.preprocessing import LabelEncoder

X_train = np.array(['MOBILE', 'NOTEBOOK', 'DESKTOP'])
X_test = np.array(['MOBILE', 'NOTEBOOK', 'TABLET'])

encoder = LabelEncoder()
encoder.fit(X_train)
x_train_encoded = encoder.transform(X_train)
print(x_train_encoded)
print(encoder.classes_)
print('\n')

for label in np.unique(X_test):
    if label not in encoder.classes_:
        encoder.classes_ = np.append(encoder.classes_, label)

x_test_encoded  = encoder.transform(X_test)
print(x_test_encoded)
print(encoder.classes_)
print('\n')

result = encoder.inverse_transform([2, 1, 0, 3])
print(result)
print('\n')















###########################################################################
분류 - 예측 대상의 속성(설명변수)을 입력받아서  목표변수(종속변수)가 갖고 있는 
카테고리(범주형) 값 중 하나의 값으로 예측하는 분석 방법
분류 분석 유형(알고리즘) -KNN, SVM, Decision Tree, Logistic Regression

KNN -새로운 관측값이 주어지면 기존 데이터 중에서 가장 속성이 비슷한 k개의 이웃을 먼저 찾아서 
가까운 이웃들이 갖고 있는 목표변수(종속변수)값과 같은 값으로 분류 , 예측
최근접점을 몇개로 할 것인지 지정하는  K는 홀수, 작은 값 설정 권장
KNN은 기존 데이터 사이의 거리를 재서 이웃을 뽑습니다.=> 거리 측정 방법에 따라 결과가 달라지는 알고리즘
※ 설명변수들을 정규화 (sklearn.preprocessing모듈의 StandardScaler())
훈련 데이터와 검증 데이터 분리 - sklearn.model selection, sklearn.preprocessing모듈의 train_test_split()
학습(훈련)으로부터 만들어진 모델의 예측 능력(정확도, 재현율, F1) 평가에 사용되는 도구- confusion_matrix()
예측 능력(정확도, 재현율, F1) 평가 지표 계산 - sklearn.metrics모듈의  classification_report()

KNN의 하이퍼파라미터 - k개수,  거리측정 방법
K가 작을 경우  overfitting
K가 커질수록  경우 underfitting 


SVM - 데이터를 오직 공간상의 정보(선)만으로 이진 분류 분석 할때 사용
         데이터 간의 마진을 최대가 되는 선을 그어 분류
3차원 데이터, 2차원의 면으로 데이터를 집단 분류- 커널 트릭, 커널 함수 매핑
SVM은 동일한 분류 값을 갖는 데이터끼리 같은 공간에 위치하도록 벡터 공간을 여러 조각으로 나눌 수 있는 분류 방법
SVM은 노이즈에 영향을 받지 않으며, overfiting될 가능성이 낮음
SVM 의 하이퍼파라미터 - cost, gamma(r), kernal


한번에 하나씩 설명변수를 사용해서 예측가능한 규칙들의 집합을 생성하는 알고리즘 
데이터를 분석해서 데이터 사이에 존재하는 패턴을 예측 가능한 규칙들의 조합으로 표현->나무모향
root node ->규칙 조건으로 분기 -> ... -> leaf node 또는 ternimal node
ternimal node들의 데이터 개수의 합 = root node의 데이터 개수
분류된 데이터 집합 수는 ternimal node의 수가 됨
범주형 데이터, 연속형 수치 데이터 모두 분류, 예측 가능
sklearn.tree모듈의 DecisionTreeClassifier()
DecisionTree 하이퍼 파라미터 - 각 노드의 순도는 증가시키고 , 불순도(불확실성)는 감소
분류오차(가지 분기 기준)


군집(cluster) - 데이터(관측값)가 가지는 여러 속성들을 분석해서 서로 비슷한 특성을 갖는 데이터끼리 그룹핑하는 알고리즘
클러스터내의 데이터들은 유사한 속성을 가지며 다른 클러스터와의 속성은 완전히 구별되는 속성을 가진다
정답이 없는 비지도 학습
K-Means -  유사한 데이터들의 클러스터 중심점까지의 거리를 이용
sklearn.cluster  모듈 - KMeans(n_clusters= , )
분류된 클러스터 결과 값은 KMeans객체.labels_


















