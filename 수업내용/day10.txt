conda install scipy scikit-learn
##############로지스틱 회귀분석 실습 ##########################################
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

score=[86,70,61,87,69, 55,70,44,51,64, 80,50,68,72,90, 93,85,74,81,88, 92,97,77,78,98]
grade=[3.61, 2.93, 3.14, 4.00, 3.23,  3.89, 3.66, 3.51, 2.53, 3.61,  2.93, 3.14, 4.00, 3.23, 2.53, 3.23, 3.89, 3.66, 3.51, 3.89,  3.66, 3.51, 2.53 ,3.14, 4.00]
_pass = [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1]

df = pd.DataFrame( {"score":score, "grade": grade, "_pass":_pass})
print(df.info())

X=df[['score', 'grade']]
Y=df[['_pass']]

# train data 와 test data를 7:3 비율로 분리
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)   


from sklearn.linear_model import LogisticRegression 
logR = LogisticRegression() 
logR.fit(X_train, Y_train)   #학습

print('정확도: ' , logR.score(X_train, Y_train))
print('정확도: ' , logR.score(X_test, Y_test))

#Confusion Matrix기반 정확률, 지지율, F1계수, 재현율을 계산해서 보고서 반환
from sklearn.metrics import classification_report
y_predict = logR.predict(X_test)
print(classification_report(Y_test, y_predict ))   #실제 합격/불합격 테스트 데이터,  모형으로부터 예측된 합격/불합격 테스트 데이터 



방법2 :
import statsmodels.api as sm
logit = sm.Logit(df['_pass'], X)  #로지스틱 회귀분석 실행
result = logit.fit()
print(result.summary2())
print(result.params)   # 종속변수에 영향을 미치는 정도 파악  

# score의 유의확률 0.0138 ,  grade의 유의확률 0.0164   은 
유의수준  0.05(95%)에서 종속변수에 영향을 주는 유의한 변수임을 확인할 수 있다.

#합격 여부에 영향을 미치는 변수의 영향도
 score의    0.132019 
grade   -2.620532

############################################################
로지스틱 회귀 분석을 수행하시오

weather.csv파일을 읽어서 Temp, Sunshine,  Humidity, Pressure, Cloud, RainToday , RainTomorrow 특성을 읽어서 dataframe으로 생성하고
RainTomorrow 변수(특성)을  로짓변환 (출력범위를 [0,1]로 조정) 합니다.

데이터를 train data 와 test data=> 7:3 비율로 분리하여 
로지스틱 회귀분석을 수행하고, 모델의 정확도를 출력하고
Temp, Sunshine,  Humidity, Pressure, Cloud가 내일 비가 올것이라고 예보하는 영향도를 평가하시오






##############선형 회귀분석 실습 ##########################################
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#1단계: 데이터 준비
df = pd.read_csv("./datas/auto-mpg.csv", header=None)
print(df.info()) 

#컬럼 이름 (변수, 특성 이름) 지정
df.columns=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']
print(df.head())

pd.set_option('display.max_columns', 10)
print(df.head())

#2단계: 데이터 탐색
print(df.info()) 
print(df.describe())
print(df['horsepower'].unique())  

# horsepower열에서 ?를 NaN값으로 대체
df['horsepower'].replace('?', np.nan, inplace=True) 
#horsepower열이 NaN인 행을 삭제
df.dropna(subset=['horsepower'], axis=0, inplace=True)
#문자열 데이터를 실수형 데이터로 변환
df['horsepower'] = df['horsepower'].astype('float')
print(df.describe())

#3단계 : 분석에 사용할 특성(열, 변수) 선택 (연비, 실린더, 마력, 중력)
ndf = df[[ 'mpg', 'cylinders','horsepower', 'weight' ]]
print(ndf.head())

#종속변수(mpg)와 다른 변수('cylinders','horsepower', 'weight')간의 선형관계여부 확인
# matplotlib로 산점도 그리기
ndf.plot(kind='scatter', x='weight', y='mpg', c='coral', s=10, figsize=(10, 5))
plt.show()
plt.close()

#seaborn으로 산점도 그리기
fig = plt.figure(figsize(10, 5))
ax1 = fig.add_subplot(1, 2, 1)
ax2 = fig.add_subplot(1, 2, 2)
sns.regplot(x='weight', y='mpg', data=ndf, ax=ax1)  #회귀선을 기본적으로 표시해줌
sns.regplot(x='weight', y='mpg', data=ndf, ax=ax1, fit_reg=False)
plt.show()
plt.close()

sns.jointplot(x='weight', y='mpg', data=ndf)
sns.jointplot(x='weight', y='mpg', data=ndf, kind='reg')  #회귀선 표시
plt.show()
plt.close()

sns.pairplot(ndf)
plt.show()
plt.close()


# 4단계 : 훈련 데이터와 테스트 데이터로 분리
X= ndf[['weight']]   #독립변수 X : 무게
Y=ndf['mpg']    #종속변수 Y : 연비

# train data 와 test data를 7:3 비율로 분리
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10)  #랜덤 추출 seed값

print('train data  개수 :', len(X_train))
print('test data  개수 :', len(X_test))

# 5단계 : 단순회귀분석 - 학습
from sklearn.linear_model import LinearRegression  #선형회귀 라이브러리의 선형회귀분석 모듈 

lr = LinearRegression()  #단순 선형회귀분석 객체 생성

lr.fit(X_train, Y_train)  #학습

r_square = lr.score(X_test, Y_test) # 결정 계수 계산
print(r_square )    #결정 계수 : 0.6822458558299325

print('기울기 a : ', lr.coef_)
print('절편 b : ', lr.intercept_)

#기울기 a :  [-0.00775343]
# 절편 b :  46.710366257280086

y_predict =lr.predict(X)   #독립변수에 대한 예측된 종속변수값 

plt.figure(figsize=(10, 5))
ax1 = sns.distplot(Y, hist=False, label='Y')
ax2 = sns.distplot(y_predict, hist=False, label='y_predict', ax=ax1)
plt.show()
plt.close()

##############다항  회귀분석 실습 ##########################################
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#1단계: 데이터 준비
df = pd.read_csv("./datas/auto-mpg.csv", header=None)
print(df.info()) 

#컬럼 이름 (변수, 특성 이름) 지정
df.columns=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']

# horsepower열에서 ?를 NaN값으로 대체
df['horsepower'].replace('?', np.nan, inplace=True) 
#horsepower열이 NaN인 행을 삭제
df.dropna(subset=['horsepower'], axis=0, inplace=True)
#문자열 데이터를 실수형 데이터로 변환
df['horsepower'] = df['horsepower'].astype('float')

#3단계 : 분석에 사용할 특성(열, 변수) 선택 (연비, 실린더, 마력, 중력)
ndf = df[[ 'mpg', 'cylinders','horsepower', 'weight' ]]


# 4단계 : 훈련 데이터와 테스트 데이터로 분리
X= ndf[['weight']]   #독립변수 X : 무게
Y=ndf['mpg']    #종속변수 Y : 연비

# train data 와 test data를 7:3 비율로 분리
from sklearn.model_selection import train_test_split
X_train, X_tset, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10)  #랜덤 추출값 10


# 5단계 : 단순회귀분석 - 학습
from sklearn.linear_model import LinearRegression  #선형회귀 라이브러리의 선형회귀분석 모듈 
from  sklearn.preprocessing import PolynomialFeatures  #다항식 변환

#다항식 변환
poly = PolynomialFeatures(degree=2)  # 2차항 적용
x_train_poly =poly.fit_transform(X_train)   # X학습데이터를 2차항으로 변형
print(x_train_poly.shape)
print(X_train.shape)

lr = LinearRegression()  #단순 선형회귀분석 객체 생성

lr.fit(x_train_poly, Y_train)  #학습


x_test_poly =poly.fit_transform(X_test) 
r_square = lr.score(x_test_poly, Y_test) # 결정 계수 계산
print(r_square )    #결정 계수 :    0.7087009262975685


print('기울기 a : ', lr.coef_)
print('절편 b : ', lr.intercept_)

#기울기 a :     [ 0.00000000e+00 -1.85768289e-02  1.70491223e-06]
# 절편 b :  62.58071221573144

y_test_predict = lr.predict(x_test_poly)  #test 데이터에 대한 모델의 예측값 구하기

fig = plt.figure(figsize=(10, 5))
ax = fig.add_subplot(1,1, 1)
ax.plot(X_train, Y_train, 'o', label='Train Data')
ax.plot(X_test, y_test_predict, 'r+', label='Predicted Value')  #학습한 회귀선
ax.legend(loc='best')
plt.xlabel('weight')
plt.ylabel('mpg')
plt.show()
plt.close()



#전체 데이터 X 를 2차항으로 변형
X_poly = poly.fit_trasform(X)
y_predict = lr.predict(X_poly)   #전체 데이터 X에 대한 모델의 예측값 반환
fig = plt.figure(figsize=(10, 5))
ax1 = sns.distplot(Y, hist=False, label="Y")
ax2 = sns.distplot(y_predict, hist=False, label="Y_predict", ax=ax1)
plt.show()
plt.close()

 
######################다중  회귀분석 실습 ##########################################
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#1단계: 데이터 준비
df = pd.read_csv("./datas/auto-mpg.csv", header=None)
print(df.info()) 

#컬럼 이름 (변수, 특성 이름) 지정
df.columns=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']

# horsepower열에서 ?를 NaN값으로 대체
df['horsepower'].replace('?', np.nan, inplace=True) 
#horsepower열이 NaN인 행을 삭제
df.dropna(subset=['horsepower'], axis=0, inplace=True)
#문자열 데이터를 실수형 데이터로 변환
df['horsepower'] = df['horsepower'].astype('float')

#3단계 : 분석에 사용할 특성(열, 변수) 선택 (연비, 실린더, 마력, 중력)
ndf = df[[ 'mpg', 'cylinders','horsepower', 'weight' ]]


# 4단계 : 훈련 데이터와 테스트 데이터로 분리
X= ndf[['cylinders', 'horsepower', 'weight']]   #독립변수 X : 무게
Y=ndf['mpg']    #종속변수 Y : 연비


# train data 와 test data를 7:3 비율로 분리
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=10)  #랜덤 추출값 10

#5단계 : 다중 회귀분석  
from sklearn.linear_model import LinearRegression  #선형회귀 라이브러리의 선형회귀분석 모듈 

lr = LinearRegression()  #단순 선형회귀분석 객체 생성

lr.fit(X_train, Y_train)  #학습 => 모델 생성

r_square = lr.score(X_test, Y_test) # 결정 계수 계산
print(r_square )    #결정 계수 :  

print('기울기 a : ', lr.coef_)
print('절편 b : ', lr.intercept_)

#기울기 a :  
# 절편 b :   

y_predict =lr.predict(X_test)   #독립변수에 대한 예측된 종속변수값 

plt.figure(figsize=(10, 5))
ax1 = sns.distplot(Y_test, hist=False, label='Y_test')
ax2 = sns.distplot(y_predict, hist=False, label='y_predict', ax=ax1)
plt.show()
plt.close()










#########################################################################
데이터를 이어 붙이기   - merge, join, concatenate
데이터 분리 (분리 크기 선택, 데이터 표본 위치,  동일한 키의 변수값 기준) - cut, qcut, groupby
groupby()함수의 반환 객체 - GroupBy(그룹 연산을 위한 모든 필요 정보를 가지고 있음)
GroupBy객체에 컬럼이름, 컬럼이름이 담긴 배열로 색인 가능 - 반환객체타입 (SeriesGroupBy, DataFrameGroupBy)
groupby()로 분리된 데이터들의 개수를 확인 - GroupBy객체.size()
분리->함수적용(agg(), apply()) -> 병합

행 인덱스( 또는 기준열)을 제외한 나머지 모든(열)을  행으로 이어붙여서 새로운 데이터 프레임을 생성(wide구조 - long구조) : stack()
동일한 컬럼 값을 가지는 로우들을 열로 이어붙여서 새로운 데이터 프레임을 생성(long구조 -> wide 구조) : unstack()

행으로 사용할 키, 열로 사용할 키를 지정해서 정렬된 데이터를 반환하는  새로운 데이터 프레임을 생성 함수 : pivot_table()
교차 테이블 생성 - crosstab()