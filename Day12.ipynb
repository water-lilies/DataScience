{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/water-lilies/DataScience/blob/master/Day12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcBKj8HSGnu6",
        "colab_type": "text"
      },
      "source": [
        "2019.12.23\n",
        "\n",
        "\n",
        "http://10.5.4.100:8080/python.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WbVOsvQGzBC",
        "colab_type": "text"
      },
      "source": [
        "## 11일차 review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R30bWKUkGl7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "속성( 컬럼, 변수 )\n",
        "\n",
        "\n",
        "선형적 관계 확인?\n",
        "=> 산점도를 그려서 확인한다.\n",
        "\n",
        "\n",
        "두 변수의 기울기와 절편을 확인하기위해\n",
        "python scikit-learn의 liner regression 사용\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRb_HO_mdaY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "분류 \n",
        "- 예측 대상의 속성(설명변수)을 입력받아서  목표변수(종속변수)가 갖고 있는 \n",
        "카테고리(범주형) 값 중 하나의 값으로 예측하는 분석 방법\n",
        "\n",
        "분류 분석 유형(알고리즘) \n",
        "-KNN, SVM, Decision Tree, Logistic Regression\n",
        "\n",
        "\n",
        "KNN \n",
        "-새로운 관측값이 주어지면 기존 데이터 중에서 가장 속성이 비슷한 k개의 이웃을 먼저 찾아서 \n",
        "가까운 이웃들이 갖고 있는 목표변수(종속변수)값과 같은 값으로 분류 , 예측\n",
        "최근접점을 몇개로 할 것인지 지정하는  K는 홀수, 작은 값 설정 권장\n",
        "\n",
        "KNN은 기존 데이터 사이의 거리를 재서 이웃을 뽑습니다.\n",
        "=> 거리 측정 방법에 따라 결과가 달라지는 알고리즘\n",
        "※ 설명변수들을 정규화 (sklearn.preprocessing모듈의 StandardScaler())\n",
        "\n",
        "훈련 데이터와 검증 데이터 분리 \n",
        "- sklearn.model selection, sklearn.preprocessing모듈의 train_test_split()\n",
        "\n",
        "학습(훈련)으로부터 만들어진 모델의 예측 능력(정확도, 재현율, F1) 평가에 사용되는 도구\n",
        "- confusion_matrix()\n",
        "\n",
        "예측 능력(정확도, 재현율, F1) 평가 지표 계산 \n",
        "- sklearn.metrics모듈의  classification_report()\n",
        "\n",
        "\n",
        "KNN의 하이퍼파라미터 \n",
        "- k개수,  거리측정 방법\n",
        "\n",
        "K가 작을 경우  overfitting\n",
        "K가 커질수록  경우 underfitting \n",
        "\n",
        "\n",
        "SVM \n",
        "- 데이터를 오직 공간상의 정보(선)만으로 이진 분류 분석 할때 사용\n",
        "  데이터 간의 마진을 최대가 되는 선을 그어 분류\n",
        "\n",
        "3차원 데이터, 2차원의 면으로 데이터를 집단 분류\n",
        "- 커널 트릭, 커널 함수 매핑\n",
        "\n",
        "SVM은 동일한 분류 값을 갖는 데이터끼리 같은 공간에 위치하도록 벡터 공간을 여러 조각으로 나눌 수 있는 분류 방법\n",
        "\n",
        "SVM은 노이즈에 영향을 받지 않으며, overfiting될 가능성이 낮음\n",
        "\n",
        "SVM 의 하이퍼파라미터 -\n",
        " cost, gamma(r), kernal\n",
        "\n",
        "\n",
        "한번에 하나씩 설명변수를 사용해서 예측가능한 규칙들의 집합을 생성하는 알고리즘 \n",
        "데이터를 분석해서 데이터 사이에 존재하는 패턴을 예측 가능한 규칙들의 조합으로 표현\n",
        "->나무모향\n",
        "\n",
        "root node ->규칙 조건으로 분기 -> ... -> leaf node 또는 ternimal node\n",
        "\n",
        "ternimal node들의 데이터 개수의 합 = root node의 데이터 개수\n",
        "\n",
        "분류된 데이터 집합 수는 ternimal node의 수가 됨\n",
        "\n",
        "범주형 데이터, 연속형 수치 데이터 모두 분류, 예측 가능\n",
        "\n",
        "sklearn.tree모듈의 DecisionTreeClassifier()\n",
        "\n",
        "DecisionTree 하이퍼 파라미터 \n",
        "- 각 노드의 순도는 증가시키고 , 불순도(불확실성)는 감소\n",
        "\n",
        "분류오차(가지 분기 기준)\n",
        "\n",
        "\n",
        "군집(cluster) \n",
        "- 데이터(관측값)가 가지는 여러 속성들을 분석해서 서로 비슷한 특성을 갖는 데이터끼리 그룹핑하는 알고리즘\n",
        "\n",
        "클러스터내의 데이터들은 유사한 속성을 가지며 다른 클러스터와의 속성은 완전히 구별되는 속성을 가진다\n",
        "\n",
        "정답이 없는 비지도 학습\n",
        "K-Means \n",
        "-  유사한 데이터들의 클러스터 중심점까지의 거리를 이용\n",
        "\n",
        "sklearn.cluster  모듈 \n",
        "- KMeans(n_clusters= , )\n",
        "\n",
        "분류된 클러스터 결과 값은 KMeans객체.labels_\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}